---
layout: post
title: Leetcode
categories:
- Data Structures and Algorithms
---

### 322. Coin Change
Key is to adopt an auxiliary array count[amount + 1].  
count[i] denotes the minimum coin count to get target value i.  

**Approach 1: Recursive DP - Top down**  
1. start from the target amount
2. substract it by each of the coins
3. call helper method itself to get the minimum count for that substracted amount
4. iterate through each coin to find the minimum count
5. add the minimum coin number by 1 to get the answer
6. remember this answer for this particular target amount to save time

**Approach 2: Iterative DP - Bottom up**  
1. start from amount 0 which needs 0 coins and add up the amount by 1 in each iteration
2. iterate through each coin
3. find the minimum count for each amount - coin in the count array before the target amount

---
### 349. Intersection of Two Arrays
array N length: n   
array M length: m   
n < m   
**Approach 1: HashSet**  
Add the smaller array into HashSet so that the space occupied is smaller.  
Time Complexity: **O(n + m)**  
Space Complexity: **O(n)**  

**Approach 2: sort + binary search**  
sort the smaller array and use binary search in it to find each element of the larger array.  
Better than approach 1 if array is too big to fit in memory
Time Complexity: **O(nlogn + mlogn)**  
Space Complexity: **O(1)**  

**Approach 3: sort + merge sorted arrays**  
Time Complexity: **O(nlogn + mlogm)**  
Space Complexity: **O(1)**  
Not as good as approach 2.   

---
### 88. Merge Sorted Array
Array A length: n, B length: m  
Brute Force: **O(n * m)**, compare from left, insert one by one at the front, shift to the right.  
Since the empty spots are at right side, how about comparing from right?  
Time complexity: **O(n + m)**  


---
### 4. Median of Two Sorted Arrays
**Approach 1: Find kth: O(log(m + n))**  
Find median problem can be generalized to find kth smallest number.
Let's say array A has n numbers, B has m numbers.  
1. Compare (k/2)th numbers in both arrays.
2. Drop the left part of the smaller number, since we are sure the kth number is not in that part.  
3. k = k - k / 2 (careful: not k = k / 2), continue 1 and 2 until k = 1.

<img src="/assets/images/i2.png" width="600"/>

In the step 1, if A is short of k / 2 numbers:
<img src="/assets/images/i3.png" width="600"/>
One thing we are sure about is that the kth number is not in the first k / 2 numbers of B. So drop that part of B.  
Imagine both arrays extended to infinite length, followed by infinite numbers of Integer.MAX_VALUE. This doesn't affect the result of finding kth smallest number. So if the startIndex + k / 2 is out of bound, just assume the element is Integer.MAX_VALUE.


---
### 139. Subarray Sum Closest
To find the subarray sum closest to 0 instead of 0, brute force is O(n^2) which is to find all subarrays. It's impossible to achieve O(n). We can consider calculating all prefix sums and sort them so that the adjacent prefix sums produce the minimum difference. Minimum difference between two prefix sums means closest subarray sum. Then we need to get the corresponding index to those two prefix sums. To do this, we can write a wrapper class to wrap the prefix sum and its index.   
Time Complexity: **O(nlogn)**  

---
### 325. Maximum Size Subarray Sum Equals k
**Prfix Sum**
`Sum of a subarray[i : j] = prefixSum[j + 1] - prefixSum[i]`  
To find a subarray sum equals k, it means `prefixSum[j + 1] = prefixSum[i] + k`   
We can use a HashMap to store each prefixSum and its index. If there's a duplicate prefixSum, just ignore it because we need to find the maximum length.  
   
---
### 53. Maximum Subarray
Brute force is O(n^2) because there are n ^ 2 subarrays.  
**Approach 1: dynamic programming O(n)**  
`int[] dp = new dp[nums.length];`   
dp[i] denotes the max sum of subarray ends with nums[i]. So we have:  
`dp[i + 1] = dp[i] > 0 ? dp[i] + nums[i + 1] : nums[i + 1];`  
Maximum subarray sum is maximum of dp array. Since we don't need the previous dp elements, we can optimize the space by using `int dp` instead of an array.  

**Approach 2: prefix sum O(n)**   
prefixSum[i + 1] denotes the sum of the first i + 1 elements, i.e. subarray[0 : i].   
`Sum of a subarray[i : j] = prefixSum[j + 1] - prefixSum[i]`  
For each subarray ending with nums[j], the maximum subarray sum depends on finding the minimum prefixSum[i].   

---
### 215. Kth Largest Element in an Array
**Quick Select**  
Use the thought in quick sort, where we partition the array by two parts based on comparison with a pivot. In quick sort, we continue sorting in two parts, while in this problem, we don't care about another part if it doesn't consist of the kth largest element. So after partition, we can drop half of the array on average.  
{% highlight java %}
T(n) = O(n) + T(n / 2)
     = O(n) + O(n / 2) + O(n / 4) + .. + O(1)
     = O(n) 
{% endhighlight %}

---
### LintCoe 545. Top k Largest Numbers II

Complexity Analysis:  

| Approach | add() Time | topk() Time | Space Complexity |
| --- | --- | --- | --- |
| quick select | O(1) | O(n) | O(n) |
| min heap | O(logk) | O(klogk) | O(k) |
| max heap | O(logn) | O(klogn) | O(n) |
| sort | O(1) | O(nlogn) | O(n) |
   
Obviously, max heap and sort approaches are worse than the other two. There's no need to keep all numbers in heap.  
It depends on how big the k is to decide which one of quick select and min heap is better. If n >> k, min heap is better, vice versa. 

---
### LintCode 612. K Closest Points
**Approach 1: Brute Force**  
Calculate distance and sort by distance.  
Time Complexity: **O(nlogn)**

**Approach 2: Quick Select**  
Time Complexity:

**Approach 3: Heap**  
Write a comparator to make the least closest point be root of the heap. Add each point to the heap, once the size is greater than k, poll the least closest point.   
Time Complexity: **O(nlogk + klogk)**  
At most k points be in heap, and we offer n points to heap. After that, poll all k closest points into results.  
   
**Approach 4: Heapify**  
Time Complexity: **O(n + klogn)**  
When n >> k, it's very fast.

--- 

### 23. Merge k Sorted Lists
Signature of the method:  
`public ListNode mergeKLists(ListNode[] lists)`  
Intuitive thinking is to compare each head node in the lists, add the smallest one to result, and make the next node of the smallest one to be the new head.   
So the brute force method costs **O(nk)**, n is the total number of nodes in all lists, k is the number of lists.    
When k is very large, accurately if bigger than logn, it's even worse than merging all lists at the first place and sort the whole list, which costs O(nlogn).   
   
**Approach 1: PriorityQueue**  
Add each node in the array into the heap, everytime we poll, we get the min value node of the k nodes. Then we add the next node of that min node to heap unless it's null.  
KEY: Since the elements in PriorityQueue are ListNode, we have to pass in a comparator to the PQ.  
{% highlight java %}
PriorityQueue<ListNode> pq = new PriorityQueue<>(lists.length, 
                                                    new NodeComparator());

public class NodeComparator implements Comparator<ListNode> {
    @Override
    public int compare(ListNode n1, ListNode n2) {
        return n1.val - n2.val;
    }
}
{% endhighlight %}

Also, the maximum number of elements will be k which is the number of the sorted lists.  
Time Complexity: **O(nlogk)**   
n is total number of elements, k is number of sorted lists.   
There will be at most k nodes in the heap, so the hight of the heap is logk, and add and poll a node into and from it costs O(logk), and we do that for n times.   
   
**Approach 2: Bottom-up pair by pair merge**  
As in the following picture, starting from the bottom, we merge each pair of lists, and merge the merged lists in pairs, and do that recursively. In this way, every level up, it costs O(n), and there are logk levels, so the time complexity is **O(nlogk)**  
<img src="/assets/images/i1.png" width="800"/>
  
**Approach 3: Divide and Conquer (like Merge Sort)**  
It's actually quite like approach 2, only implement the top-down process with a recursion (divide). Approach 2 starts from the bottom, using an iteration to go through the array of ListNode pair by pair. Approach 3 starts from the top, viewing the array as a whole and divide it by 2 recursively until only one node is left. And then merge like in the approach 2.     


---
### 264. Ugly Number II
**Approach 1**  
Use a PriorityQueue as a min heap. The heap starts with 1 in it. Get a min value from the heap and multiply it with 2, 3, 5 and add the results to the heap. Every time poll() we can get a min value which ensures the order.   
However, this process generates duplicates, eg. 2 * 3 = 3 * 2.  
PriorityQueue allows duplicates so HashSet can be used to ensure there's no duplicates in the heap.  

Note: be aware of integer overflow!!   
Imagine in the final round, min value is supposed to be say 536,870,912, but the heap still contains many numbers that are greater than this min, which may exceeds the upper bound of integer. This will cause negative numbers in the heap and these negative numbers will become the min value.   
   
Time complexity: **O(nlogn)**  
Everytime we poll a number, we add it multiplied by 2, 3, 5 into the heap. Add operation for heap is O(logn). And we need to poll n times to find the nth ugly number.   
   
**Approach 2**  
Imagin a list of ugly numbers 1, 2, 3, 4, 5, 6, 8, 9, ...   
And 3 pointers for multipliers 2, 3, 5, corresponding p2, p3, p5, all pointing at 1. After we multiply 1 by 2, 3, 5, we add the min value to the list which is 2, and we move the p2 to the next element which is 2, since we already multiplied the 1 with 2. Later, we compare 2 * 2, 1 * 3, 1 * 5, and we add 3, and move p3 to next...   
Time complexity: **O(n)**  

---
### 380. Insert Delete GetRandom O(1)
Design a data structure that supports all following operations in average O(1) time.
1. insert(val)
2. remove(val)
3. getRandom

Consider 3 possible data structure:  
1. LinkedList: insert and remove are O(1), but for getRandom, we have to iterate to a random node which takes O(n)
2. HashMap: insert and remove are O(1), but can't get a random number from it.
3. ArrayList: insert and getRandom are O(1), but remove takes O(n) because of shifting.

We can consider a combination of ArrayList and HashMap. To find the index of the value to be removed in O(1), we can use a HashMap to store the value and its corresponding index. To avoid shifting caused by remove(), we can just move the last element to replace the removed one, since we don't care the order. 

---
### 146. LRU Cache
Design and implement a data structure for Least Recently Used (LRU) cache. It should support the following operations:   
1. get(key)
2. put(key, value)

It's natural to think of LinkedList which is fast to insert and delete a node, whereas an array takes O(n) to delete a element in the middle and maintain the order at the same time.  
For get(), we need to find the node and move it to the front.  
For put(), we also need to find the node and update it or create a new node and move it to the front. If it reaches the capacity, we need to delete the oldest node at the end.  
LinkedList takes O(1) to delete and insert a node. But it takes O(n) to find the node. To improve the performance to O(1), a HashMap can store the mapping between the key and the node.  
However, to delete a node, we have to know the previous node. Doubly linked list can solve the problem, but a more concise way is to store the mapping between the key and the previous node.   
Therefore, a **LinkedList and a HashMap** can implement the get and put operation in **O(1)**.  
LinkedHashMap can help.  

---
### 387. First Unique Character in a String
It's easy to solve the problem in O(n) using HashMap or an array of size 26.   
Let's consider its follow-up question: iterate through the string for only once. Like to get the first unique character in a stream, where add and getFirstUnique operation both take O(1).  
   
We can use the same thought in LRU cache with a combination of HashMap and LinkedList.  
Let's maintain a LinkedList of characters that are unique, and the head of the list is the first unique char. HashMap stores the information about which node the char is in. Once a new char comes in which is already in the HashMap, we just delete the node.

---
### 4. Median of Two Sorted Arrays
<https://leetcode.com/problems/median-of-two-sorted-arrays/description/>

{% highlight java %}
public double findMedianSortedArrays(int[] nums1, int[] nums2) {
    int n = nums1.length + nums2.length;
    
    // odd number
    if ((n & 1) == 1) {
        return findKth(nums1, 0, nums2, 0, n / 2 + 1);
    }
    
    // even number
    return (findKth(nums1, 0, nums2, 0, n / 2) + findKth(nums1, 0, nums2, 0, n / 2 + 1)) / 2.0;
}

// find the kth smallest number in the two arrays
private int findKth(int[] nums1, int start1, int[] nums2, int start2, int k) {
    if (start1 >= nums1.length) {
        return nums2[start2 + k - 1];
    }
    
    if (start2 >= nums2.length) {
        return nums1[start1 + k - 1];
    }
    
    if (k == 1) {
        return Math.min(nums1[start1], nums2[start2]);
    }
    
    int half1 = Integer.MAX_VALUE;
    int half2 = Integer.MAX_VALUE;
    
    if (start1 + k / 2 - 1 < nums1.length) {
        half1 = nums1[start1 + k / 2 - 1];
    }
    
    if (start2 + k / 2 - 1 < nums2.length) {
        half2 = nums2[start2 + k / 2 - 1];
    }
    
    if (half1 > half2) {
        return findKth(nums1, start1, nums2, start2 + k / 2, k - k / 2);
    } 
    
    return findKth(nums1, start1 + k / 2, nums2, start2, k - k / 2);
}

{% endhighlight %}

---

### 50. Pow(x, n)
<https://leetcode.com/problems/powx-n/description/>

Recursive method is relatively easy. Lets discuss about the iterative one.  
Let's consider the exponent n in binary representation. Say, n = 9

`9 = (1001)2 = 2 ^ 3 + 2 ^ 0`

Therefore, pow(x, 9) equals  
`x ^ 9 = x ^ (2 ^ 3 + 2 ^ 0) = (x ^ (2 ^ 3)) * (x ^ (2 ^ 0))`    

So if **ith** bit is 1, we multiply the ans by `x ^ (2 ^ i)`. (the least significant is 0th)   
For `i = 0, 1, 2, ...`, we multiply the ans by `x ^ 1, x ^ 2, x ^ 4, x ^ 8, ...`

{% highlight java %}
public double myPow(double x, int n) {
    double ans = 1;
    if (n < 0) {
        x = 1 / x;
    }
    long absN = Math.abs((long)n);
    
    while (absN > 0) {
        if ((absN & 1) == 1) {
            ans *= x;
        }
        
        absN >>= 1;
        x *= x;
    }
    
    return ans;
}
{% endhighlight %}
Note:  
When calculating absolute values, be careful with the integer overflow. Turn it into long in advance.  

---
### 230. Kth Smallest Element in a BST
<https://leetcode.com/problems/kth-smallest-element-in-a-bst/>   

**Approach 1: Inorder Traversal - Iterative**    
    
**Time complexity:**    
O(max(k, h)), minimum time will be on average O(h) because we need to go all the way down to the leftmost node and then starting counting till k.   
**Space complexity**:   
O(h), h is height of the tree   

{% highlight java %}
public int kthSmallest(TreeNode root, int k) {
    Stack<TreeNode> stack = new Stack<>();
    TreeNode curr = root;
    while (curr != null) {
        stack.push(curr);
        curr = curr.left;
    }
    
    while (!stack.isEmpty()) {
        TreeNode node = stack.pop();
        k--;
        if (k == 0) {
            return node.val;
        }
        
        TreeNode ptr = node.right;
        while (ptr != null) {
            stack.push(ptr);
            ptr = ptr.left;
        }
    }
    
    return -1;
}
{% endhighlight %}

**Approach 2: Add a count field in node - recursive**   

If the BST is modified (insert/delete operations) often and we need to find the kth smallest frequently...     
O(k) is too slow in the case when k is closer to number of nodes.     
If we can reconstruct the node structure of the tree, we can add a count field to indicate the number of nodes in the node's subtree, including itself.    

**Time complexity**:   
kthSmallest(): O(h), h is the height of the tree, because each recursion we can go one level deeper by choosing left of right subtree.  
insert/delete operation: O(h), O(h) to find the right place to insert/detele and O(h) to update each upper level parent's count.   
**Space complexity**:   
O(1). (Not counting the space of the new tree because imagine we edit the original tree structure to include the count field in the first place)

{% highlight java %}
class Solution {
    public int kthSmallest(TreeNode root, int k) {
        Node newRoot = buildCountTree(root);
        return kthSmallest(newRoot, k);
    }

    private int kthSmallest(Node root, int k) {
        if (root.left != null) {
            if (root.left.count < k - 1) {
                return kthSmallest(root.right, k - root.left.count - 1);
            } else if (root.left.count == k - 1) {
                return root.val;
            } else {
                return kthSmallest(root.left, k);
            }
        } else if (k == 1) {
            return root.val;
        } else {
            return kthSmallest(root.right, k - 1);
        }
    }
    
    private Node buildCountTree(TreeNode node) {
        if (node == null) {
            return null;
        }
        
        Node root = new Node(node.val);
        root.left = buildCountTree(node.left);
        root.right = buildCountTree(node.right);
        
        if (root.left != null) {
            root.count += root.left.count;
        }
        if (root.right != null) {
            root.count += root.right.count;
        }
        return root;
    }
    
    private static class Node {
        int val;
        int count;
        Node left, right;
        
        Node(int v) {
            val = v;
            count = 1;
        }
    }
}
{% endhighlight %}